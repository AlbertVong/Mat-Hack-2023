{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gplearn.genetic import SymbolicClassifier\n",
    "import pandas as pd\n",
    "import random\n",
    "import graphviz\n",
    "import scipy\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from sympy import *\n",
    "from IPython.display import display, Math\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "#Dictionary for functions in gplearn\n",
    "converter = {\n",
    "    'sub': lambda x, y : x - y,\n",
    "    'div': lambda x, y : x/y,\n",
    "    'mul': lambda x, y : x*y,\n",
    "    'add': lambda x, y : x + y,\n",
    "    'neg': lambda x    : -x,\n",
    "    'exp': lambda x, y : x**y,\n",
    "    'sin': lambda x    : sin(x),\n",
    "    'cos': lambda x    : cos(x),\n",
    "    'inv': lambda x: 1/x,\n",
    "    'sqrt': lambda x: x**0.5,\n",
    "    'pow3': lambda x: x**3\n",
    "}\n",
    "\n",
    "\n",
    "def multiclass_to_binary(labels, select_id):\n",
    "    \"\"\"Converts multiclass labels to select_id vs all\n",
    "    \"\"\"\n",
    "    to_binary = lambda val: 1 if val == select_id else 0\n",
    "    to_binary_vec = np.vectorize(to_binary)\n",
    "    labels_1vsall = to_binary_vec(labels)\n",
    "    return labels_1vsall\n",
    "\n",
    "\n",
    "def vis_expr(classifier, save_prefix):\n",
    "    \"\"\"Function for prettifying expressions output by the symbolic classifier (denoted as SR_Classifier)\n",
    "    Converts program expression -> sympy -> latex -> janky matplotlib workaround for latex formulas\n",
    "    \"\"\"\n",
    "    expression = latex(sympify((str(SR_classifier._program)), locals=converter))\n",
    "    fig, ax = plt.subplots(figsize=(0.1,0.1))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.axis('off')\n",
    "    plt.text(0, 0,'$%s$'%expression, size=15)\n",
    "    plt.savefig(f'{save_prefix}_expression.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def save_model(classifier, save_prefix):\n",
    "    formula = str(SR_classifier._program)\n",
    "    params = SR_classifier.get_params()\n",
    "    params['feature_names'] = list(params['feature_names'])\n",
    "    params['function_set'] = list(params['function_set'])\n",
    "    with open(f'{save_prefix}_params.json', 'a+') as f:\n",
    "        json.dump(params, f)\n",
    "    with open(f'{save_prefix}_formula.txt', 'a+') as f:\n",
    "        f.write(formula)\n",
    "\n",
    "        \n",
    "def plot_run(classifier):\n",
    "    run_details = classifier.run_details_\n",
    "    fig, ax1 = plt.subplots(figsize=(6,2))\n",
    "    skip_gen = 1\n",
    "    colors = ['tab:red', 'tab:blue']\n",
    "    ax1.set_ylabel('average_length', color=colors[0])\n",
    "    ax1.plot(run_details['generation'][skip_gen:], run_details['average_length'][skip_gen:], \n",
    "             label='Avg Length', color=colors[0])\n",
    "    ax1.tick_params(axis='y', labelcolor=colors[0])\n",
    "#     ax1.set_ylim(0,10)\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    ax2.set_ylabel('average_fitness', color=colors[1])  # we already handled the x-label with ax1\n",
    "    ax2.plot(run_details['generation'][skip_gen:], run_details['average_fitness'][skip_gen:], \n",
    "             label='Avg Length', color=colors[1])\n",
    "    ax2.tick_params(axis='y', labelcolor=colors[1])\n",
    "#     ax2.set_ylim(0,2.5)\n",
    "    ax1.set_xlabel('Generation')\n",
    "    plt.xlim(0,None)\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def examine_model(classifier):\n",
    "\n",
    "    ### Plot run history\n",
    "    plot_run(classifier)\n",
    "\n",
    "    ### Evaluate on test set\n",
    "    predictions = classifier.predict(features_test)\n",
    "    precision = int(100*precision_score(labels_test, predictions))\n",
    "    recall = int(100*recall_score(labels_test, predictions))\n",
    "    roc_auc = int(100*roc_auc_score(labels_test,predictions)) \n",
    "    print(f'AUC:    \\t{roc_auc}\\nPrecision: \\t{precision}\\nRecall: \\t{recall}')\n",
    "\n",
    "    ### Evaluate on the rest of the negative class set\n",
    "    # Getting the rest of the negative set features and values\n",
    "    remainder_negative_set_idx = negative_scrambled_order[n_positive_class:]\n",
    "    remainder_negative_features = neg_features[remainder_negative_set_idx,:]\n",
    "    remainder_negative_labels = neg_labels[remainder_negative_set_idx]\n",
    "    acc_neg = int(100*np.mean(remainder_negative_labels == classifier.predict(remainder_negative_features)))\n",
    "    print(f'Acc (-):    \\t{acc_neg}')\n",
    "\n",
    "    ### Visualize expression, record run\n",
    "    dt_string = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    save_prefix = f'models/c{pos_label}vsall_auc{roc_auc}_prec{precision}_reca{recall}_accn{acc_neg}_len{classifier._program.length_}_{dt_string}'\n",
    "    vis_expr(classifier, save_prefix)\n",
    "    save_model(classifier, save_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTS ###########################################################\n",
    "label_path = '../3_generate_features/final_label_array.csv'\n",
    "feat_path = '../3_generate_features/dimensionless_cropped_final_feature_array.csv'\n",
    "feat_reduction_path = 'feature_reduction/features_c1/16_iteration_feature_3_features.csv'\n",
    "pos_label = 1 \n",
    "#########################################################################\n",
    "\n",
    "### Prepare labels\n",
    "label_df = pd.read_csv(label_path).drop(columns='Unnamed: 0',errors='ignore')\n",
    "# Find unique labels and counts\n",
    "class_df = pd.DataFrame(label_df.value_counts()).reset_index()\n",
    "class_df = class_df.rename(columns={0:'population'})\n",
    "class_df['label'] = class_df.index\n",
    "display(class_df.head())\n",
    "# Convert to numerical labels\n",
    "proto2label = {proto:label for proto,label in class_df[['Prototype','label']].to_numpy()}\n",
    "label2proto = {label:proto for proto,label in class_df[['Prototype','label']].to_numpy()}\n",
    "label_df['label'] = [proto2label[proto] for proto in label_df.Prototype]\n",
    "label_df.head()\n",
    "### Define 1vsall version\n",
    "pos_proto = label2proto[pos_label]\n",
    "print(f'Predicting {pos_proto} vs. rest')\n",
    "labels_1vsall = multiclass_to_binary(label_df.label, select_id=pos_label)\n",
    "print(labels_1vsall)\n",
    "\n",
    "### Prepare features\n",
    "feat_df = pd.read_csv(feat_path).drop(columns='Unnamed: 0',errors='ignore')\n",
    "# display(feat_df.head())\n",
    "# Reduce features\n",
    "feature_reduction_df = pd.read_csv(feat_reduction_path)\n",
    "feature_reduction_feature_names = feature_reduction_df['Name'].to_numpy()\n",
    "feat_df = feat_df[feature_reduction_feature_names]\n",
    "# Add a constant column\n",
    "# feat_df['one'] = [1]*len(feat_df)\n",
    "features = feat_df.to_numpy()\n",
    "feature_names = feat_df.columns\n",
    "display(feat_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subsampling\n",
    "###############\n",
    "#Set rng seed and permutation of data examples for training\n",
    "rng = check_random_state(5)\n",
    "# Check number of dominant class examples\n",
    "n_positive_class = np.sum(labels_1vsall)\n",
    "# Dominant class boolean index\n",
    "positive_class_mask = (labels_1vsall == 1)\n",
    "# Dominant class indexing to grab for training/test set (we want 50/50 representation)\n",
    "pos_features = features[positive_class_mask,:]\n",
    "pos_labels = labels_1vsall[positive_class_mask]\n",
    "# Grabbing all negative examples of which we're going to grab a number equal to the number of dominant class\n",
    "neg_features = features[~positive_class_mask,:]\n",
    "neg_labels = labels_1vsall[~positive_class_mask]\n",
    "\n",
    "# Apply subsampling. We grab a random subset from the negative set of the same size as the positive examples\n",
    "negative_scrambled_order = rng.permutation(neg_labels.size)\n",
    "subsample_idx = negative_scrambled_order[:n_positive_class]\n",
    "# Concatenate an equal amount of negative training data to the list of positive training data so we have 50/50 class representation\n",
    "# auto-shuffling occurs later in k-fold\n",
    "features_balanced = np.concatenate((pos_features, neg_features[subsample_idx,:]),axis=0)\n",
    "labels_balanced = np.concatenate((pos_labels, neg_labels[subsample_idx]), axis=0)\n",
    "nan_count = np.sum(~np.isfinite(features_balanced))\n",
    "print(f'{nan_count} NaNs present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train-test-split \n",
    "####################\n",
    "#Generate 20-80 splits (we're going to just use one of these for the initial pass)\n",
    "skf = StratifiedKFold(n_splits=5) \n",
    "splits = skf.split(features_balanced, labels_balanced)\n",
    "# Use first generator output for train/test splits\n",
    "(train_idx, test_idx) = next(splits)\n",
    "\n",
    "# Defining train test splits using train/test indices\n",
    "features_train = features_balanced[train_idx]\n",
    "features_test =  features_balanced[test_idx]\n",
    "labels_train = labels_balanced[train_idx]\n",
    "labels_test =  labels_balanced[test_idx]\n",
    "print('Train sizes:', len(features_train), len(labels_train))\n",
    "print('Test sizes: ', len(features_test), len(labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Symbolic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_distros = {'population_size': scipy.stats.randint(500,3000),\n",
    "                 'tournament_size': scipy.stats.randint(10,500),\n",
    "#                  'parsimony_coefficient': scipy.stats.uniform(0.01, 0.001)\n",
    "             }\n",
    "base_estimator = SymbolicClassifier(init_depth=(1,5),\n",
    "                                    parsimony_coefficient=0.005,\n",
    "                                    generations=25,\n",
    "                                    p_crossover = 0.85,\n",
    "                                    p_subtree_mutation = 0.01,\n",
    "                                    p_point_mutation = 0.01,\n",
    "                                    p_hoist_mutation = 0.1,\n",
    "                                    const_range=(-10,10),\n",
    "                                    feature_names=feature_names,\n",
    "                                    n_jobs=-1, \n",
    "                                    random_state=0,\n",
    "                                    function_set={'add','sub','mul','div','max','min'}\n",
    "                                    )\n",
    "\n",
    "sh = HalvingRandomSearchCV(base_estimator, param_distributions, cv=5,\n",
    "                           min_resources=20, max_resources=100, factor=2\n",
    "                          ).fit(features_train, labels_train)\n",
    "\n",
    "examinine_model(sh.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_model(sh.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot ROC\n",
    "fpr, tpr, _ = roc_curve(labels_test,predictions)\n",
    "plt.figure()\n",
    "plt.plot( fpr, tpr, color=\"darkorange\", \n",
    "         label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color=\"k\", linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ### Train a single sym learner\n",
    "# SR_classifier = SymbolicClassifier(population_size = 500, \n",
    "#                                    generations=100,\n",
    "#                                    tournament_size = 50,\n",
    "#                                    init_depth=(1,5),\n",
    "#                                    parsimony_coefficient=0.005,\n",
    "#                                    p_crossover = 0.85,\n",
    "#                                    p_subtree_mutation = 0.01,\n",
    "#                                    p_point_mutation = 0.01,\n",
    "#                                    p_hoist_mutation = 0.1,\n",
    "#                                    const_range=(-10,10),\n",
    "#                                    feature_names=feature_names,\n",
    "#                                    n_jobs=-1, \n",
    "# #                                    verbose=1,\n",
    "#                                    random_state=1,\n",
    "#                                    function_set={'add','sub','mul','div','max','min'}\n",
    "#                                   )\n",
    "\n",
    "# SR_classifier.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing estimated probabilities\n",
    "\n",
    "estimated_classes = SR_classifier.predict_proba(remainder_negative_features)[:,1]\n",
    "\n",
    "estimated_classes[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "f29cf555f1ad55622b61a06ba1522f7bf976ada2ce369c8ede82aeb1ba1ad311"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
