{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'cropped_final_feature_array.csv'\n",
    "features = pd.read_csv(filename)\n",
    "print(features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# group feature names by units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_groups = [#['e1_Number', -- I don't think we want to encode atomic identity -- we want to be more general\n",
    "               ['e1_avg_oxi_pos', 'e1_avg_oxi_neg'],\n",
    "               ['e1_MendeleevNumber'],\n",
    "               ['e1_Column', 'e1_Row'],\n",
    "               ['e1_AtomicWeight'],\n",
    "               ['e1_MeltingT'],\n",
    "               ['e1_CovalentRadius'],\n",
    "               ['e1_NsValence','e1_NpValence', 'e1_NdValence', 'e1_NfValence', 'e1_NValence',\n",
    "                'e1_NsUnfilled', 'e1_NpUnfilled', 'e1_NdUnfilled', 'e1_NfUnfilled', 'e1_NUnfilled'],\n",
    "               ['e1_Electronegativity'],\n",
    "#                ['e1_GSbandgap'],\n",
    "#                ['e1_GSmagmom'],\n",
    "               ['e1_GSvolume_pa']]\n",
    "\n",
    "for i in range(len(feat_groups)):\n",
    "    feat_groups[i] += [name.replace('e1','e2') for name in feat_groups[i]]\n",
    "\n",
    "print(feat_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get pairwise combinations of feature names per group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dimensionless_features = []\n",
    "all_dimensionless_feature_names = []\n",
    "\n",
    "for group in feat_groups:\n",
    "    pairs_of_features = list(combinations(group,2))\n",
    "    print(pairs_of_features)\n",
    "    offset = 0\n",
    "    # Add offset for electron count features to avoid div by zero\n",
    "    if ('e1_NpValence' in group) or ('e1_avg_oxi_pos' in group): offset = 1\n",
    "    # Calculate all the dimensionless versions of the feature\n",
    "    for feature_pair in pairs_of_features:\n",
    "        f1, f2 = feature_pair[0], feature_pair[1]\n",
    "        all_dimensionless_features += [((features[f1]+offset) / (features[f2]+offset)).to_numpy()]\n",
    "#         all_dimensionless_feature_names += [f\"e1/e2_{f1[3:]}\"]\n",
    "        all_dimensionless_feature_names += [f\"{f1}/{f2}\"]\n",
    "\n",
    "        all_dimensionless_features += [(((features[f1]+offset) + (features[f2]+offset)) / (features[f1]+offset)).to_numpy()]\n",
    "#         all_dimensionless_feature_names += [f\"(e1+e2)/e1_{f1[3:]}\"]\n",
    "        all_dimensionless_feature_names += [f\"({f1}+{f2})/{f1}\"]\n",
    "        \n",
    "        all_dimensionless_features += [(((features[f1]+offset) - (features[f2]+offset)) / (features[f1]+offset)).to_numpy()]\n",
    "#         all_dimensionless_feature_names += [f\"(e1-e2)/e1_{f1[3:]}\"]\n",
    "        all_dimensionless_feature_names += [f\"({f1}-{f2})/{f1}\"]\n",
    "\n",
    "        all_dimensionless_features += [(((features[f1]+offset) + (features[f2]+offset)) / (features[f2]+offset)).to_numpy()]\n",
    "#         all_dimensionless_feature_names += [f\"(e1+e2)/e2_{f1[3:]}\"]\n",
    "        all_dimensionless_feature_names += [f\"({f1}+{f2})/{f2}\"]\n",
    "\n",
    "        all_dimensionless_features += [(((features[f1]+offset) - (features[f2]+offset)) / (features[f2]+offset)).to_numpy()]\n",
    "#         all_dimensionless_feature_names += [f\"(e1-e2)/e2_{f1[3:]}\"]\n",
    "        all_dimensionless_feature_names += [f\"({f1}-{f2})/{f2}\"]\n",
    "\n",
    "dimensionless_feature_array = np.vstack(all_dimensionless_features).T\n",
    "dimensionless_feature_df = pd.DataFrame(data = dimensionless_feature_array,columns=all_dimensionless_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dimensionless_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionless_feature_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge new dimensionless features with existing dimensionless features\n",
    "existing_features = ['max_ionic_char', 'avg_ionic_char', 'chg_dispro']\n",
    "dimensionless_feature_df = dimensionless_feature_df.merge(features[existing_features], left_index=True, right_index=True)\n",
    "dimensionless_feature_df['chg_dispro'] = dimensionless_feature_df.chg_dispro.astype(int)\n",
    "dimensionless_feature_df.to_csv(f'dimensionless_{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for no NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_nans_per_feature = np.sum(dimensionless_feature_df.isna().to_numpy(),axis=0)\n",
    "\n",
    "print(sum(number_of_nans_per_feature))\n",
    "print(number_of_nans_per_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "f29cf555f1ad55622b61a06ba1522f7bf976ada2ce369c8ede82aeb1ba1ad311"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
