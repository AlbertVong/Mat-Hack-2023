{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "67e0c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from gplearn.genetic import SymbolicClassifier\n",
    "import pandas as pd\n",
    "import random\n",
    "# import graphviz\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import time\n",
    "\n",
    "\n",
    "def prep_labels(label_df):\n",
    "    ### Prepare labels\n",
    "    # Find unique labels and counts\n",
    "    class_df = pd.DataFrame(label_df.value_counts()).reset_index()\n",
    "    class_df = class_df.rename(columns={0:'population'})\n",
    "    class_df['label'] = class_df.index\n",
    "    # Convert to numerical labels\n",
    "    proto2label = {proto:label for proto,label in class_df[['Prototype','label']].to_numpy()}\n",
    "#     label2proto = {label:proto for proto,label in class_df[['Prototype','label']].to_numpy()}\n",
    "    label_df['label'] = [proto2label[proto] for proto in label_df.Prototype]\n",
    "    return label_df, class_df, proto2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd9efe1",
   "metadata": {},
   "source": [
    "## Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cf4149e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1605\n",
      "1: 1606\n"
     ]
    }
   ],
   "source": [
    "### CONSTANTS ###########################################################\n",
    "label_path = '../3_generate_features/final_label_array.csv'\n",
    "feat_path = '../3_generate_features/dimensionless_cropped_final_feature_array.csv'\n",
    "SEED = 0\n",
    "N_SPLITS = 5\n",
    "select_prototypes = ['Laves(cub)#MgCu2', 'Laves(2H)#MgZn2']\n",
    "#########################################################################\n",
    "\n",
    "### Import data\n",
    "label_df, class_df, proto2label = prep_labels(pd.read_csv(label_path).drop(columns='Unnamed: 0',errors='ignore'))\n",
    "feat_df = pd.read_csv(feat_path).drop(columns='Unnamed: 0',errors='ignore')\n",
    "\n",
    "### Convert to binary (1 vs rest), where 1 => select_prototype\n",
    "label_binary = np.zeros(len(label_df))\n",
    "for select_proto in select_prototypes:\n",
    "    label_binary = label_binary | (label_df.Prototype == select_proto)\n",
    "label_df['label_binary'] = label_binary.astype(int)\n",
    "\n",
    "### Subsample to attain balance\n",
    "n_pos = np.where(label_df.label_binary == 1)[0].size\n",
    "pos_idxs = rng.permutation(np.where(label_df.label_binary == 1)[0])\n",
    "neg_idxs = rng.permutation(np.where(label_df.label_binary == 0)[0])\n",
    "rng = np.random.default_rng(seed=SEED)\n",
    "select_neg_idxs = neg_idxs[:n_pos]\n",
    "extra_neg_idxs = neg_idxs[n_pos:]\n",
    "select_idxs = rng.permutation(np.concatenate([select_neg_idxs, pos_idxs]))\n",
    "bal_feat_df = feat_df.iloc[select_idxs]\n",
    "bal_label_df = label_df.iloc[select_idxs]\n",
    "\n",
    "### Train-test-split\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED) \n",
    "train_idx, test_idx = next(skf.split(bal_feat_df, bal_label_df.label_binary))\n",
    "feat_df_train = bal_feat_df.iloc[train_idx]#.copy()\n",
    "feat_df_test =  bal_feat_df.iloc[test_idx]#.copy()\n",
    "label_df_train = bal_label_df.iloc[train_idx]#.copy()\n",
    "label_df_test =  bal_label_df.iloc[test_idx]#.copy()\n",
    "print(f'0: {len(label_df_train[label_df_train.label_binary == 0])}')\n",
    "print(f'1: {len(label_df_train[label_df_train.label_binary == 1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f033706b",
   "metadata": {},
   "source": [
    "## Instantiate learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "50b8e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, class_weight='balanced', criterion='log_loss', \n",
    "                             random_state=SEED, ccp_alpha=0.000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945bd701",
   "metadata": {},
   "source": [
    "## Active learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0dba449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super epoch 0: Score = 0.914 -- (Precision | Recall | AccNeg) = (0.91 | 0.93 | 0.9)\n",
      "Super epoch 1: Score = 0.934 -- (Precision | Recall | AccNeg) = (0.95 | 0.95 | 0.9)\n",
      "Super epoch 2: Score = 0.955 -- (Precision | Recall | AccNeg) = (0.98 | 0.98 | 0.9)\n",
      "Super epoch 3: Score = 0.968 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 4: Score = 0.968 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 5: Score = 0.968 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 6: Score = 0.968 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 7: Score = 0.968 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 8: Score = 0.968 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 9: Score = 0.968 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 10: Score = 0.968 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 11: Score = 0.968 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 12: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 13: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 14: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 15: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 16: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 17: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 18: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 19: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 20: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 21: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 22: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 23: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 24: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 25: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 26: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 27: Score = 0.967 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 28: Score = 0.966 -- (Precision | Recall | AccNeg) = (1.0 | 1.0 | 0.9)\n",
      "Super epoch 29: Score = 0.966 -- (Precision | Recall | AccNeg) = (0.99 | 1.0 | 0.9)\n",
      "Exhausted OOB samples\n",
      "Super epoch 30: Score = 0.965 -- (Precision | Recall | AccNeg) = (0.99 | 1.0 | 0.9)\n"
     ]
    }
   ],
   "source": [
    "### Constants\n",
    "INITIAL_FRAC = 0.05 # fraction of training data to train on initially\n",
    "AL_BATCH_SIZE = 100 # number of samples to train\n",
    "SCORE_THRESH = 0.99\n",
    "MAX_SUPER_EPOCHS = 50\n",
    "\n",
    "### Start active learning loop\n",
    "# t_idxs = list(\n",
    "score = 0\n",
    "current_batch_idxs = feat_df_train.index[:int(INITIAL_FRAC*len(feat_df_train))]\n",
    "oob_idxs = feat_df_train.index[int(INITIAL_FRAC*len(feat_df_train)):]\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ### Check for base cases\n",
    "    if len(oob_idxs) == 0:\n",
    "        print('Exhausted OOB samples')\n",
    "        break\n",
    "    if score >= SCORE_THRESH:\n",
    "        print('Reached thershold score')\n",
    "        break\n",
    "    if i >= MAX_SUPER_EPOCHS:\n",
    "        print('Reached max number of generations')\n",
    "        break\n",
    "    \n",
    "    ### Train on current batch\n",
    "    start = time.time()\n",
    "    batch_feats = feat_df_train.loc[current_batch_idxs].to_numpy()\n",
    "    batch_labels = label_df_train.loc[current_batch_idxs].label_binary.to_numpy()\n",
    "    clf.fit(batch_feats, batch_labels)\n",
    "    \n",
    "    ### Calc acc on batch, out-of-batch -- entire set? (or remaining set?) (TODO should i allow retraining on the same example? --> No, defeats the purpose of mo\n",
    "    batch_predict_labels = clf.predict(batch_feats)\n",
    "#     batch_prec = precision_score(batch_labels, batch_predict_labels)\n",
    "#     batch_rec = recall_score(batch_labels, batch_predict_labels)\n",
    "    oob_feats = feat_df_train.loc[oob_idxs].to_numpy()\n",
    "    oob_labels = label_df_train.loc[oob_idxs].label_binary.to_numpy()\n",
    "    oob_predict_labels = clf.predict(oob_feats)\n",
    "#     batch_prec = precision_score(batch_labels, batch_predict_labels)\n",
    "#     batch_rec = recall_score(batch_labels, batch_predict_labels)\n",
    "    prec = precision_score(np.concatenate([batch_labels,oob_labels]),\n",
    "                           np.concatenate([batch_predict_labels, oob_predict_labels]))\n",
    "    rec = recall_score(np.concatenate([batch_labels,oob_labels]),\n",
    "                           np.concatenate([batch_predict_labels, oob_predict_labels]))\n",
    "    \n",
    "    ### Calc score on other negative examples\n",
    "    extra_feats = feat_df.iloc[extra_neg_idxs].to_numpy()\n",
    "    extra_labels = label_df.iloc[extra_neg_idxs].label_binary.to_numpy()\n",
    "    extra_predict_labels = clf.predict(extra_feats)\n",
    "    extra_score = np.mean(extra_labels == extra_predict_labels)\n",
    "\n",
    "    ### Calculate aggregate score\n",
    "    score = np.mean([prec,rec,extra_score])\n",
    "\n",
    "    ### Update current batch -- separate N worst examples as new batch\n",
    "    oob_losses = (oob_labels == oob_predict_labels)\n",
    "    sorted_idxs = list(list(zip(*sorted(zip(oob_losses, oob_idxs))))[1])\n",
    "    if len(sorted_idxs) < AL_BATCH_SIZE:\n",
    "        batch_idxs = sorted_idxs\n",
    "        oob_idxs = []\n",
    "        print('Exhausted OOB samples')\n",
    "    else:\n",
    "        batch_idxs = sorted_idxs[:AL_BATCH_SIZE]\n",
    "        oob_idxs = sorted_idxs[AL_BATCH_SIZE:]\n",
    "    \n",
    "    ### Report superepoch details\n",
    "#     print(f'Elapsed Time: {np.round(time.time()-start,1)}s')\n",
    "    print(f'Super epoch {i}: Score = {np.round(score,3)} -- (Precision | Recall | AccNeg) = ({np.round(prec,2)} | {np.round(rec,2)} | {np.round(extra_score,2)})')\n",
    "#     print(f'Super epoch {i}: Score on Neg: {np.round(extra_score,2)}')#  |  Recall: {np.round(extra_rec,2)}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e55bdd",
   "metadata": {},
   "source": [
    "## Examine Failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca84da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bcfe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
